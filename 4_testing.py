import torch
import torch.nn as nn
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from pathlib import Path
from PIL import Image
import os
from sklearn.metrics import classification_report, confusion_matrix, f1_score
import numpy as np
from tqdm import tqdm

import time

from Class_Dataset import MyDataset
from Class_Model import MyModule

import matplotlib.pyplot as plt
import seaborn as sns
###########################    CONFIGURE   #############################

DATA_ROOT_PATH = Path("E:/ECG_Thanh/ECG-compact-model-/ECG_Classification/data")
MODEL_PATH = Path("E:/ECG_Thanh/ECG-compact-model-/ECG_Classification/model_save/ecg_model.pth")
COMPACT_MODEL_PATH = Path("E:/ECG_Thanh/ECG-compact-model-/ECG_Classification/model_save/ecg_model_compact.pth")
QUANTIZED_MODEL_PATH = Path("E:/ECG_Thanh/ECG-compact-model-/ECG_Classification/model_save/ecg_model_quantized_1.pth")
BATCH_SIZE = 128

# ====================== Inference & Evaluation ======================

def evaluate():
    torch.serialization.add_safe_globals([MyModule])
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load model
    #model = MyModule()
    model = torch.load(MODEL_PATH, weights_only=False)
    # model = torch.load(MODEL_PATH, map_location=device, weights_only=False)

    #model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.to(device)
    model.eval()

    # Transform
    transform = transforms.Compose([
        transforms.ToTensor()
    ])

    # Load test data
    test_dataset = MyDataset(root_dir=DATA_ROOT_PATH/'test_images', transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    all_preds = []
    all_labels = []

    start_time = time.time() #B·∫Øt ƒë·∫ßu t√≠nh th·ªùi gian

    #L√† ch·∫°y m√¥ h√¨nh tr√™n t·∫≠p test, l·∫•y d·ª± ƒëo√°n (preds) v√† so s√°nh v·ªõi nh√£n th·∫≠t (labels)
    with torch.no_grad(): #T·∫Øt ch·∫ø ƒë·ªô t√≠nh gradient ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ v√† tƒÉng t·ªëc, ko c·∫ßn h·ªçc 
        for inputs, labels in tqdm(test_loader, desc="üîç Testing"): #inputs: batch ·∫£nh scalogram, labels: nh√£n t∆∞∆°ng ·ª©ng (class th·ª±c t·∫ø)
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs) #D·ªØ li·ªáu ƒëi qua m√¥ h√¨nh (N·∫øu m√¥ h√¨nh c√≥ l·ªõp softmax/logits ·ªü cu·ªëi, outputs s·∫Ω l√† [batch_size, num_classes])
            _, preds = torch.max(outputs, 1) #L·∫•y ch·ªâ s·ªë class c√≥ gi√° tr·ªã l·ªõn nh·∫•t ·ªü m·ªói h√†ng ‚Üí ch√≠nh l√† class m√† m√¥ h√¨nh d·ª± ƒëo√°n
                #preds: vector d·ª± ƒëo√°n class (vd: [0, 1, 2, ...])

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            #preds v√† labels ƒë∆∞·ª£c chuy·ªÉn v·ªÅ CPU v√† numpy ƒë·ªÉ: D·ªÖ d√πng v·ªõi sklearn (d√πng t√≠nh accuracy, confusion matrix, F1-score).
    end_time = time.time() #K·∫øt th√∫c t√≠nh th·ªùi gian
    num_images = len(all_labels) #S·ªë l∆∞·ª£ng ·∫£nh trong t·∫≠p test
    total_time = end_time - start_time #T√≠nh th·ªùi gian ch·∫°y
    print(f"\nƒê√£ predict {num_images} ·∫£nh trong {total_time:.2f} gi√¢y")
    print(f"T·ªëc ƒë·ªô: {(num_images/total_time):.2f} ·∫£nh/s")   

    # Evaluation 
    print("‚úÖ Evaluation Result:") #In ra ti√™u ƒë·ªÅ
    print("Confusion Matrix:")
    cm = confusion_matrix(all_labels, all_preds)
    print(cm)

    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, digits=4)) #digits=4: l√†m tr√≤n ƒë·∫øn 4 ch·ªØ s·ªë th·∫≠p ph√¢n

    #T√≠nh Macro F1-score cho t·ª´ng l·ªõp, r·ªìi l·∫•y trung b√¨nh c·ªông
    print(f"F1 Score (macro): {f1_score(all_labels, all_preds, average='macro'):.4f}") 

    #Weighted F1: T√≠nh F1-score t·ª´ng l·ªõp, nh∆∞ng c√¢n theo s·ªë l∆∞·ª£ng m·∫´u ·ªü m·ªói l·ªõp
    #Ph√π h·ª£p khi c√°c l·ªõp m·∫•t c√¢n b·∫±ng (unbalanced)
    print(f"F1 Score (weighted): {f1_score(all_labels, all_preds, average='weighted'):.4f}")

    # V·∫Ω confusion matrix d·∫°ng ph·∫ßn trƒÉm v·ªõi heatmap
    cm_percent = cm.astype('float')
    plt.figure(figsize=(8,6))
    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', cbar=True, square=True)
    plt.title('Confusion Matrix (%)')
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    plt.tight_layout()
    plt.show()
        # L∆∞u k·∫øt qu·∫£ ra file txt
    with open("test_result.txt", "w", encoding="utf-8") as f:
        f.write(f"ƒê√£ predict {num_images} ·∫£nh trong {total_time:.2f} gi√¢y\n")
        f.write(f"T·ªëc ƒë·ªô: {(num_images/total_time):.2f} ·∫£nh/s\n\n")
        f.write("Confusion Matrix:\n")
        f.write(np.array2string(cm))
        f.write("\n\nClassification Report:\n")
        f.write(classification_report(all_labels, all_preds, digits=4))
        f.write(f"\nF1 Score (macro): {f1_score(all_labels, all_preds, average='macro'):.4f}\n")
        f.write(f"F1 Score (weighted): {f1_score(all_labels, all_preds, average='weighted'):.4f}\n")

    print("‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o test_result.txt")
if __name__ == '__main__':
    evaluate()
